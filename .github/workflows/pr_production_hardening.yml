name: "PR - Production Hardening"

on:
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write

jobs:
  harden:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Apply all fixes
        id: apply-all-fixes
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require("fs");
            const path = require("path");
            const core = require("@actions/core");
            const exists = p => fs.existsSync(p);
            const read = p => fs.readFileSync(p, "utf8");
            const write = (p, c) => { fs.mkdirSync(path.dirname(p), { recursive: true }); fs.writeFileSync(p, c); };
            const rm = p => { if (exists(p)) fs.rmSync(p, { recursive: true, force: true }); };
            let changes = [];

            // monitor.py: import + logger fixes
            if (exists("monitor.py")) {
              let t = read("monitor.py");
              const before = t;
              t = t.replace(/from requests\.adapters import HTTPAdapter,\s*Retry/g,
                            "from requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry");
              const loggerRe = /def setup_logger\(verbosity: int = 1\)[\s\S]*?return logger/;
              const newLogger =
`def setup_logger(verbosity: int = 1) -> logging.Logger:
    logger = logging.getLogger("instagram_monitor")
    logger.setLevel(logging.DEBUG)
    fmt = logging.Formatter("[%(levelname)s] %(message)s")
    if logger.handlers:
        ch = logger.handlers[0]
        ch.setLevel(logging.DEBUG if verbosity > 1 else logging.INFO)
        ch.setFormatter(fmt)
    else:
        ch = logging.StreamHandler(sys.stdout)
        ch.setLevel(logging.DEBUG if verbosity > 1 else logging.INFO)
        ch.setFormatter(fmt)
        logger.addHandler(ch)
    return logger`;
              if (loggerRe.test(t)) t = t.replace(loggerRe, newLogger);
              if (t !== before) { write("monitor.py", t); changes.push("monitor.py"); }
            }

            // workflows: ensure `export INPUT` where we "Build user matrix"
            const wfDir = ".github/workflows";
            if (exists(wfDir)) {
              for (const name of fs.readdirSync(wfDir)) {
                if (!name.endsWith(".yml") && !name.endsWith(".yaml")) continue;
                const p = path.join(wfDir, name);
                let txt = read(p); const before = txt;
                if (/Build user matrix/.test(txt) &&
                    /if \[ -z "\$INPUT" \]; then INPUT="therock"; fi/.test(txt) &&
                    !/export INPUT/.test(txt)) {
                  txt = txt.replace(/if \[ -z "\$INPUT" \]; then INPUT="therock"; fi/,
                                    'if [ -z "$INPUT" ]; then INPUT="therock"; fi\n          export INPUT');
                }
                if (txt !== before) { write(p, txt); changes.push(p); }
              }
            }

            // repo cleanup
            ["config_server.py","instagram_monitor_config.py","config.json.example","test_setup.py",
             "instagram_profile_pic_empty.jpeg","placeholder_svg.svg"].forEach(f => { if (exists(f)) { rm(f); changes.push(f); } });

            // remove tracked runtime data
            if (exists("monitoring_data/therock")) { rm("monitoring_data/therock"); changes.push("monitoring_data/therock"); }
            if (exists("data")) for (const f of fs.readdirSync("data")) if (f !== ".gitkeep") { rm(path.join("data", f)); changes.push(`data/${f}`); }

            // ensure dirs + .gitkeep
            fs.mkdirSync("monitoring_data", { recursive: true });
            fs.mkdirSync("data", { recursive: true });
            if (!exists("monitoring_data/.gitkeep")) { write("monitoring_data/.gitkeep",""); changes.push("monitoring_data/.gitkeep"); }
            if (!exists("data/.gitkeep")) { write("data/.gitkeep",""); changes.push("data/.gitkeep"); }

            // .gitignore
            const gitignore =
`__pycache__/
*.py[cod]
.env
.venv
venv/

# Runtime outputs - NEVER commit
monitoring_data/
data/
!monitoring_data/.gitkeep
!data/.gitkeep

# Logs / OS
*.log
.DS_Store
`;
            if (!exists(".gitignore") || read(".gitignore") !== gitignore) { write(".gitignore", gitignore); changes.push(".gitignore"); }

            // requirements
            const reqs =
`instaloader>=4.11
requests>=2.31.0
urllib3>=2.0.0
python-dateutil>=2.8.2
pytz>=2023.3
`;
            if (!exists("requirements.txt") || read("requirements.txt") !== reqs) { write("requirements.txt", reqs); changes.push("requirements.txt"); }

            core.setOutput("changed", String(changes.length > 0));

      - name: Create Pull Request
        if: steps.apply-all-fixes.outputs.changed == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: "fix: production hardening (imports/logger), workflow input export, cleanup & hygiene"
          title: "Fix: production hardening & workflow hygiene"
          body: |
            - Fixes `monitor.py` imports and logger handler update
            - Ensures `export INPUT` wherever the user matrix is built
            - Removes orphaned files and tracked runtime data
            - Adds `.gitignore` to keep outputs out of git
            - Pins `requirements.txt` to safe versions
          branch: fix/production-hardening

      - name: No-op
        if: steps.apply-all-fixes.outputs.changed != 'true'
        run: echo "No changes needed; repo already hardened."
